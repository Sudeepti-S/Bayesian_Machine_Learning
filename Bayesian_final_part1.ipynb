{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sudeepti Surapaneni, Sania Rasheed, Arti Patel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/theano/configdefaults.py:560: UserWarning: DeprecationWarning: there is no c++ compiler.This is deprecated and with Theano 0.11 a c++ compiler will be mandatory\n",
      "  warnings.warn(\"DeprecationWarning: there is no c++ compiler.\"\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('C:/Users/Arti Patel/Desktop/bayesian_ml/final')\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3058: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('train-balanced-sarcasm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>704656</td>\n",
       "      <td>0</td>\n",
       "      <td>Those don't remove the fumes from film and pap...</td>\n",
       "      <td>kwirky88</td>\n",
       "      <td>Darkroom</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-04</td>\n",
       "      <td>4/1/15 18:04</td>\n",
       "      <td>You could always try a few small standing filt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>368240</td>\n",
       "      <td>0</td>\n",
       "      <td>Insulation is not limited to timber constructi...</td>\n",
       "      <td>_I_Have_Opinions_</td>\n",
       "      <td>polandball</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-04</td>\n",
       "      <td>4/15/16 15:03</td>\n",
       "      <td>Our glorious Norwegian homes are made of wood,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7270</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes, please use the search bar to see if your ...</td>\n",
       "      <td>sombrez</td>\n",
       "      <td>meirl</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>12/14/16 0:48</td>\n",
       "      <td>This has been posted before?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>326996</td>\n",
       "      <td>0</td>\n",
       "      <td>I think it may also be that this picture has b...</td>\n",
       "      <td>fagnerd</td>\n",
       "      <td>pokemon</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-08</td>\n",
       "      <td>8/24/16 1:45</td>\n",
       "      <td>Because memes have more value than good art. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630659</td>\n",
       "      <td>0</td>\n",
       "      <td>I didn't say you are Hitler, but yes, what you...</td>\n",
       "      <td>andyetanotherkiwi</td>\n",
       "      <td>relationships</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015-07</td>\n",
       "      <td>7/21/15 19:22</td>\n",
       "      <td>Let's be reasonable and limit the hyperbole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                            comment  \\\n",
       "704656     0  Those don't remove the fumes from film and pap...   \n",
       "368240     0  Insulation is not limited to timber constructi...   \n",
       "7270       1  Yes, please use the search bar to see if your ...   \n",
       "326996     0  I think it may also be that this picture has b...   \n",
       "630659     0  I didn't say you are Hitler, but yes, what you...   \n",
       "\n",
       "                   author      subreddit  score   ups  downs     date  \\\n",
       "704656           kwirky88       Darkroom    2.0   2.0    0.0  2015-04   \n",
       "368240  _I_Have_Opinions_     polandball   14.0  14.0    0.0  2016-04   \n",
       "7270              sombrez          meirl    8.0  -1.0   -1.0  2016-12   \n",
       "326996            fagnerd        pokemon    1.0   1.0    0.0  2016-08   \n",
       "630659  andyetanotherkiwi  relationships   17.0  17.0    0.0  2015-07   \n",
       "\n",
       "          created_utc                                     parent_comment  \n",
       "704656   4/1/15 18:04  You could always try a few small standing filt...  \n",
       "368240  4/15/16 15:03  Our glorious Norwegian homes are made of wood,...  \n",
       "7270    12/14/16 0:48                       This has been posted before?  \n",
       "326996   8/24/16 1:45  Because memes have more value than good art. I...  \n",
       "630659  7/21/15 19:22        Let's be reasonable and limit the hyperbole  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010827, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14879,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how many unique subreddits in original dataset\n",
    "df['subreddit'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, '1', '0'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning label column:\n",
    "#checking to see format of 1's and 0's: not all are numeric format, dropping 1 row that has no label value\n",
    "proper_labels = ['0','1',0,1]\n",
    "df = df.query('label in @proper_labels')\n",
    "df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1010826, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate length of comment feature\n",
    "df['comment'] = df['comment'].astype('str')\n",
    "word_count = df['comment'].str.split()\n",
    "df['comment_count'] = word_count.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate length of parent column feature\n",
    "df['parent_comment'] = df['parent_comment'].astype('str')\n",
    "word_count_parent = df['parent_comment'].str.split()\n",
    "df['parent_comment_count'] = word_count_parent.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>parent_comment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>10/16/16 23:55</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>11/1/16 0:24</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>9/22/16 21:45</td>\n",
       "      <td>They're favored to win.</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>10/18/16 21:03</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>12/30/16 17:00</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            comment     author  \\\n",
       "0     0                                         NC and NH.  Trumpbart   \n",
       "1     0  You do know west teams play against west teams...  Shbshb906   \n",
       "2     0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "3     0  This meme isn't funny none of the \"new york ni...  icebrotha   \n",
       "4     0                    I could use one of those tools.  cush2push   \n",
       "\n",
       "            subreddit  score  ups  downs     date     created_utc  \\\n",
       "0            politics    2.0 -1.0   -1.0  2016-10  10/16/16 23:55   \n",
       "1                 nba   -4.0 -1.0   -1.0  2016-11    11/1/16 0:24   \n",
       "2                 nfl    3.0  3.0    0.0  2016-09   9/22/16 21:45   \n",
       "3  BlackPeopleTwitter   -8.0 -1.0   -1.0  2016-10  10/18/16 21:03   \n",
       "4  MaddenUltimateTeam    6.0 -1.0   -1.0  2016-12  12/30/16 17:00   \n",
       "\n",
       "                                      parent_comment  comment_count  \\\n",
       "0  Yeah, I get that argument. At this point, I'd ...              3   \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...             14   \n",
       "2                            They're favored to win.             19   \n",
       "3                         deadass don't kill my buzz             12   \n",
       "4  Yep can confirm I saw the tool they use for th...              7   \n",
       "\n",
       "   parent_comment_count  \n",
       "0                    17  \n",
       "1                    27  \n",
       "2                     4  \n",
       "3                     5  \n",
       "4                    18  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "AskReddit          65677\n",
       "politics           39496\n",
       "worldnews          26377\n",
       "leagueoflegends    21037\n",
       "pcmasterrace       18988\n",
       "funny              17939\n",
       "news               16891\n",
       "pics               16154\n",
       "todayilearned      14161\n",
       "nfl                14150\n",
       "nba                14146\n",
       "GlobalOffensive    13740\n",
       "AdviceAnimals      13483\n",
       "videos             12320\n",
       "gaming             11906\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top subreddit pages (by no. of comments)\n",
    "count_subreddit = df.groupby('subreddit').size().sort_values(ascending=False)\n",
    "count_subreddit.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new df with just the top ten subreddits (we leave out the \"pics\" subreddit)\n",
    "subreddit_subset = ['AskReddit','politics','worldnews','leagueoflegends','pcmasterrace','funny','news','todayilearned','nfl','nba']\n",
    "dfsub = df.query('subreddit in @subreddit_subset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(248862, 12)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of new df with subset of subreddits\n",
    "dfsub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121819, 12)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub[dfsub['label']==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8284, 12)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub[dfsub['label']=='1'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111223, 12)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub[dfsub['label']==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7536, 12)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub[dfsub['label']=='0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new subset df is 47% non sarcastic vs 53% sarcastic - almost balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by subreddit to see which subreddits are most sarcastic\n",
    "sarcasm_subreddit = df[['subreddit','label']].groupby('subreddit').sum()\n",
    "sarcasm_subreddit['label'] = sarcasm_subreddit['label'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>pokemongo</td>\n",
       "      <td>1149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EnoughTrumpSpam</td>\n",
       "      <td>821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>reddit.com</td>\n",
       "      <td>768.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ClashRoyale</td>\n",
       "      <td>683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>battlefield_one</td>\n",
       "      <td>261.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>uncensorednews</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Infinitewarfare</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>enoughsandersspam</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>deadbydaylight</td>\n",
       "      <td>157.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TickTockManitowoc</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>HillaryForPrison</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>RocketLeagueExchange</td>\n",
       "      <td>131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TheSilphRoad</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NintendoSwitch</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Political_Revolution</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       label\n",
       "subreddit                   \n",
       "pokemongo             1149.0\n",
       "EnoughTrumpSpam        821.0\n",
       "reddit.com             768.0\n",
       "ClashRoyale            683.0\n",
       "battlefield_one        261.0\n",
       "uncensorednews         245.0\n",
       "Infinitewarfare        173.0\n",
       "enoughsandersspam      163.0\n",
       "deadbydaylight         157.0\n",
       "TickTockManitowoc      147.0\n",
       "HillaryForPrison       136.0\n",
       "RocketLeagueExchange   131.0\n",
       "TheSilphRoad           117.0\n",
       "NintendoSwitch         111.0\n",
       "Political_Revolution    98.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcasm_subreddit = sarcasm_subreddit.sort_values(by='label', ascending=False)\n",
    "sarcasm_subreddit.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/su/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download package that can tokenize words and create bigrams and trigrams\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NC', 'and'), ('and', 'NH'), ('NH', '.')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test to tokenize words\n",
    "w = nltk.word_tokenize(df['comment'][0])\n",
    "w\n",
    "b = list(nltk.bigrams(w))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bigrams = [list(nltk.bigrams(i)) for i in word_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bigrams'] = my_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_trigrams = [list(nltk.trigrams(i)) for i in word_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trigrams'] = my_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>parent_comment_count</th>\n",
       "      <th>bigrams</th>\n",
       "      <th>trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>10/16/16 23:55</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>[(NC, and), (and, NH.)]</td>\n",
       "      <td>[(NC, and, NH.)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>11/1/16 0:24</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>[(You, do), (do, know), (know, west), (west, t...</td>\n",
       "      <td>[(You, do, know), (do, know, west), (know, wes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>9/22/16 21:45</td>\n",
       "      <td>They're favored to win.</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>[(They, were), (were, underdogs), (underdogs, ...</td>\n",
       "      <td>[(They, were, underdogs), (were, underdogs, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
       "      <td>icebrotha</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>10/18/16 21:03</td>\n",
       "      <td>deadass don't kill my buzz</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>[(This, meme), (meme, isn't), (isn't, funny), ...</td>\n",
       "      <td>[(This, meme, isn't), (meme, isn't, funny), (i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I could use one of those tools.</td>\n",
       "      <td>cush2push</td>\n",
       "      <td>MaddenUltimateTeam</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-12</td>\n",
       "      <td>12/30/16 17:00</td>\n",
       "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>[(I, could), (could, use), (use, one), (one, o...</td>\n",
       "      <td>[(I, could, use), (could, use, one), (use, one...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            comment     author  \\\n",
       "0     0                                         NC and NH.  Trumpbart   \n",
       "1     0  You do know west teams play against west teams...  Shbshb906   \n",
       "2     0  They were underdogs earlier today, but since G...   Creepeth   \n",
       "3     0  This meme isn't funny none of the \"new york ni...  icebrotha   \n",
       "4     0                    I could use one of those tools.  cush2push   \n",
       "\n",
       "            subreddit  score  ups  downs     date     created_utc  \\\n",
       "0            politics    2.0 -1.0   -1.0  2016-10  10/16/16 23:55   \n",
       "1                 nba   -4.0 -1.0   -1.0  2016-11    11/1/16 0:24   \n",
       "2                 nfl    3.0  3.0    0.0  2016-09   9/22/16 21:45   \n",
       "3  BlackPeopleTwitter   -8.0 -1.0   -1.0  2016-10  10/18/16 21:03   \n",
       "4  MaddenUltimateTeam    6.0 -1.0   -1.0  2016-12  12/30/16 17:00   \n",
       "\n",
       "                                      parent_comment  comment_count  \\\n",
       "0  Yeah, I get that argument. At this point, I'd ...              3   \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...             14   \n",
       "2                            They're favored to win.             19   \n",
       "3                         deadass don't kill my buzz             12   \n",
       "4  Yep can confirm I saw the tool they use for th...              7   \n",
       "\n",
       "   parent_comment_count                                            bigrams  \\\n",
       "0                    17                            [(NC, and), (and, NH.)]   \n",
       "1                    27  [(You, do), (do, know), (know, west), (west, t...   \n",
       "2                     4  [(They, were), (were, underdogs), (underdogs, ...   \n",
       "3                     5  [(This, meme), (meme, isn't), (isn't, funny), ...   \n",
       "4                    18  [(I, could), (could, use), (use, one), (one, o...   \n",
       "\n",
       "                                            trigrams  \n",
       "0                                   [(NC, and, NH.)]  \n",
       "1  [(You, do, know), (do, know, west), (know, wes...  \n",
       "2  [(They, were, underdogs), (were, underdogs, ea...  \n",
       "3  [(This, meme, isn't), (meme, isn't, funny), (i...  \n",
       "4  [(I, could, use), (could, use, one), (use, one...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bigram_sent'] = df.apply(lambda x: [], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gets polarity score for each bigram in comment column, takes a few min to run\n",
    "for index, row in df.iterrows():\n",
    "    mylist = row['bigrams']\n",
    "    for j in mylist:\n",
    "        bi_one = ''.join(j)\n",
    "        #t = mylist.index(j)\n",
    "        df['bigram_sent'][index].append(analyser.polarity_scores(bi_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "913324    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "487578    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "880235    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "725174    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "719541    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "944355    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "640808    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "674965    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "373073    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "149452    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "581652    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "621462    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "534248    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "930725    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "479511                                                   []\n",
       "62914     [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "487052    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "785574    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "532710    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "917788    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "257441    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "813357    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "492755    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "474373    [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "2175      [{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compoun...\n",
       "Name: bigram_sent, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bigram_sent'].sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#polarity scores doesn't seem to work on bigrams - we think this may be because there are a lot of \"filler/function\" words\n",
    "#still remaining in text that prevent vader from picking up on positive/negative sentiment\n",
    "#because we did not find a useful feature out of this, we did not continue finding sentiment in trigrams, the following 3\n",
    "#cells are markdown because they are not used for the purposes of this project/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['trigram_sent'] = df.apply(lambda x: [], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for index, row in df.iterrows():\n",
    "    mylist = row['trigrams']\n",
    "    for j in mylist:\n",
    "        tri_one = ''.join(j)\n",
    "        #t = mylist.index(j)\n",
    "        df['trigram_sent'][index].append(analyser.polarity_scores(tri_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['trigram_sent'].sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# use vader tool to get polarity scores on comments as a whole\n",
    "p = [analyser.polarity_scores(i) for i in dfsub['comment']]\n",
    "dfsub['polarity'] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#break out the individual neg, pos, neutral and compound scores and make columns for each\n",
    "l = list(dfsub['polarity'])\n",
    "dfsub['neg'] = [i.get('neg') for i in l]\n",
    "dfsub['neu'] = [i.get('neu') for i in l]\n",
    "dfsub['pos'] = [i.get('pos') for i in l]\n",
    "dfsub['compound'] = [i.get('compound') for i in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>parent_comment_count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>pcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>10/16/16 23:55</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.337, 'pos': 0.663, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>{'neg': 0.126, 'neu': 0.657, 'pos': 0.217, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>11/1/16 0:24</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>{'neg': 0.095, 'neu': 0.905, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>9/22/16 21:45</td>\n",
       "      <td>They're favored to win.</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't pay attention to her, but as long as s...</td>\n",
       "      <td>only7inches</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>9/2/16 10:35</td>\n",
       "      <td>do you find ariana grande sexy ?</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.868, 'pos': 0.132, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.595, 'pos': 0.405, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Trick or treating in general is just weird...</td>\n",
       "      <td>only7inches</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>10/23/16 21:43</td>\n",
       "      <td>What's your weird or unsettling Trick or Treat...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>{'neg': 0.146, 'neu': 0.854, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>{'neg': 0.25, 'neu': 0.517, 'pos': 0.233, 'com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            comment       author  \\\n",
       "0     0                                         NC and NH.    Trumpbart   \n",
       "1     0  You do know west teams play against west teams...    Shbshb906   \n",
       "2     0  They were underdogs earlier today, but since G...     Creepeth   \n",
       "5     0  I don't pay attention to her, but as long as s...  only7inches   \n",
       "6     0      Trick or treating in general is just weird...  only7inches   \n",
       "\n",
       "   subreddit  score  ups  downs     date     created_utc  \\\n",
       "0   politics    2.0 -1.0   -1.0  2016-10  10/16/16 23:55   \n",
       "1        nba   -4.0 -1.0   -1.0  2016-11    11/1/16 0:24   \n",
       "2        nfl    3.0  3.0    0.0  2016-09   9/22/16 21:45   \n",
       "5  AskReddit    0.0  0.0    0.0  2016-09    9/2/16 10:35   \n",
       "6  AskReddit    1.0 -1.0   -1.0  2016-10  10/23/16 21:43   \n",
       "\n",
       "                                      parent_comment  comment_count  \\\n",
       "0  Yeah, I get that argument. At this point, I'd ...              3   \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...             14   \n",
       "2                            They're favored to win.             19   \n",
       "5                   do you find ariana grande sexy ?             24   \n",
       "6  What's your weird or unsettling Trick or Treat...              8   \n",
       "\n",
       "   parent_comment_count                                           polarity  \\\n",
       "0                    17  {'neg': 0.0, 'neu': 0.337, 'pos': 0.663, 'comp...   \n",
       "1                    27  {'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...   \n",
       "2                     4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "5                     7  {'neg': 0.0, 'neu': 0.868, 'pos': 0.132, 'comp...   \n",
       "6                     9  {'neg': 0.146, 'neu': 0.854, 'pos': 0.0, 'comp...   \n",
       "\n",
       "     neg    neu    pos  compound  \\\n",
       "0  0.000  0.337  0.663    0.6037   \n",
       "1  0.000  0.844  0.156    0.3400   \n",
       "2  0.000  1.000  0.000    0.0000   \n",
       "5  0.000  0.868  0.132    0.2259   \n",
       "6  0.146  0.854  0.000   -0.0516   \n",
       "\n",
       "                                                 pcp  \n",
       "0  {'neg': 0.126, 'neu': 0.657, 'pos': 0.217, 'co...  \n",
       "1  {'neg': 0.095, 'neu': 0.905, 'pos': 0.0, 'comp...  \n",
       "2  {'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'comp...  \n",
       "5  {'neg': 0.0, 'neu': 0.595, 'pos': 0.405, 'comp...  \n",
       "6  {'neg': 0.25, 'neu': 0.517, 'pos': 0.233, 'com...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display\n",
    "dfsub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#same process for parent comment - vader tool implemented to find parent comment polarity scores:\n",
    "pcp = [analyser.polarity_scores(i) for i in dfsub['parent_comment']]\n",
    "dfsub['pcp'] = pcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>parent_comment_count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>pcp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>10/16/16 23:55</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.337, 'pos': 0.663, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>{'neg': 0.126, 'neu': 0.657, 'pos': 0.217, 'co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>11/1/16 0:24</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>{'neg': 0.095, 'neu': 0.905, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>9/22/16 21:45</td>\n",
       "      <td>They're favored to win.</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't pay attention to her, but as long as s...</td>\n",
       "      <td>only7inches</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>9/2/16 10:35</td>\n",
       "      <td>do you find ariana grande sexy ?</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.868, 'pos': 0.132, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.595, 'pos': 0.405, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Trick or treating in general is just weird...</td>\n",
       "      <td>only7inches</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>10/23/16 21:43</td>\n",
       "      <td>What's your weird or unsettling Trick or Treat...</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>{'neg': 0.146, 'neu': 0.854, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>{'neg': 0.25, 'neu': 0.517, 'pos': 0.233, 'com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            comment       author  \\\n",
       "0     0                                         NC and NH.    Trumpbart   \n",
       "1     0  You do know west teams play against west teams...    Shbshb906   \n",
       "2     0  They were underdogs earlier today, but since G...     Creepeth   \n",
       "5     0  I don't pay attention to her, but as long as s...  only7inches   \n",
       "6     0      Trick or treating in general is just weird...  only7inches   \n",
       "\n",
       "   subreddit  score  ups  downs     date     created_utc  \\\n",
       "0   politics    2.0 -1.0   -1.0  2016-10  10/16/16 23:55   \n",
       "1        nba   -4.0 -1.0   -1.0  2016-11    11/1/16 0:24   \n",
       "2        nfl    3.0  3.0    0.0  2016-09   9/22/16 21:45   \n",
       "5  AskReddit    0.0  0.0    0.0  2016-09    9/2/16 10:35   \n",
       "6  AskReddit    1.0 -1.0   -1.0  2016-10  10/23/16 21:43   \n",
       "\n",
       "                                      parent_comment  comment_count  \\\n",
       "0  Yeah, I get that argument. At this point, I'd ...              3   \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...             14   \n",
       "2                            They're favored to win.             19   \n",
       "5                   do you find ariana grande sexy ?             24   \n",
       "6  What's your weird or unsettling Trick or Treat...              8   \n",
       "\n",
       "   parent_comment_count                                           polarity  \\\n",
       "0                    17  {'neg': 0.0, 'neu': 0.337, 'pos': 0.663, 'comp...   \n",
       "1                    27  {'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...   \n",
       "2                     4  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "5                     7  {'neg': 0.0, 'neu': 0.868, 'pos': 0.132, 'comp...   \n",
       "6                     9  {'neg': 0.146, 'neu': 0.854, 'pos': 0.0, 'comp...   \n",
       "\n",
       "     neg    neu    pos  compound  \\\n",
       "0  0.000  0.337  0.663    0.6037   \n",
       "1  0.000  0.844  0.156    0.3400   \n",
       "2  0.000  1.000  0.000    0.0000   \n",
       "5  0.000  0.868  0.132    0.2259   \n",
       "6  0.146  0.854  0.000   -0.0516   \n",
       "\n",
       "                                                 pcp  \n",
       "0  {'neg': 0.126, 'neu': 0.657, 'pos': 0.217, 'co...  \n",
       "1  {'neg': 0.095, 'neu': 0.905, 'pos': 0.0, 'comp...  \n",
       "2  {'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'comp...  \n",
       "5  {'neg': 0.0, 'neu': 0.595, 'pos': 0.405, 'comp...  \n",
       "6  {'neg': 0.25, 'neu': 0.517, 'pos': 0.233, 'com...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = list(dfsub['pcp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "dfsub['pc_neg'] = [j.get('neg') for j in p]\n",
    "dfsub['pc_neu'] = [j.get('neu') for j in p]\n",
    "dfsub['pc_pos'] = [j.get('pos') for j in p]\n",
    "dfsub['pc_compund'] = [j.get('compound') for j in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "      <th>author</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>downs</th>\n",
       "      <th>date</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>parent_comment</th>\n",
       "      <th>...</th>\n",
       "      <th>polarity</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>pcp</th>\n",
       "      <th>pc_neg</th>\n",
       "      <th>pc_neu</th>\n",
       "      <th>pc_pos</th>\n",
       "      <th>pc_compund</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NC and NH.</td>\n",
       "      <td>Trumpbart</td>\n",
       "      <td>politics</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>10/16/16 23:55</td>\n",
       "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.337, 'pos': 0.663, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.663</td>\n",
       "      <td>0.6037</td>\n",
       "      <td>{'neg': 0.126, 'neu': 0.657, 'pos': 0.217, 'co...</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You do know west teams play against west teams...</td>\n",
       "      <td>Shbshb906</td>\n",
       "      <td>nba</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-11</td>\n",
       "      <td>11/1/16 0:24</td>\n",
       "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.156</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>{'neg': 0.095, 'neu': 0.905, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>They were underdogs earlier today, but since G...</td>\n",
       "      <td>Creepeth</td>\n",
       "      <td>nfl</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>9/22/16 21:45</td>\n",
       "      <td>They're favored to win.</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.7650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>I don't pay attention to her, but as long as s...</td>\n",
       "      <td>only7inches</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-09</td>\n",
       "      <td>9/2/16 10:35</td>\n",
       "      <td>do you find ariana grande sexy ?</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.868, 'pos': 0.132, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.2259</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.595, 'pos': 0.405, 'comp...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.595</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.5267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Trick or treating in general is just weird...</td>\n",
       "      <td>only7inches</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2016-10</td>\n",
       "      <td>10/23/16 21:43</td>\n",
       "      <td>What's your weird or unsettling Trick or Treat...</td>\n",
       "      <td>...</td>\n",
       "      <td>{'neg': 0.146, 'neu': 0.854, 'pos': 0.0, 'comp...</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.0516</td>\n",
       "      <td>{'neg': 0.25, 'neu': 0.517, 'pos': 0.233, 'com...</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            comment       author  \\\n",
       "0     0                                         NC and NH.    Trumpbart   \n",
       "1     0  You do know west teams play against west teams...    Shbshb906   \n",
       "2     0  They were underdogs earlier today, but since G...     Creepeth   \n",
       "5     0  I don't pay attention to her, but as long as s...  only7inches   \n",
       "6     0      Trick or treating in general is just weird...  only7inches   \n",
       "\n",
       "   subreddit  score  ups  downs     date     created_utc  \\\n",
       "0   politics    2.0 -1.0   -1.0  2016-10  10/16/16 23:55   \n",
       "1        nba   -4.0 -1.0   -1.0  2016-11    11/1/16 0:24   \n",
       "2        nfl    3.0  3.0    0.0  2016-09   9/22/16 21:45   \n",
       "5  AskReddit    0.0  0.0    0.0  2016-09    9/2/16 10:35   \n",
       "6  AskReddit    1.0 -1.0   -1.0  2016-10  10/23/16 21:43   \n",
       "\n",
       "                                      parent_comment  ...  \\\n",
       "0  Yeah, I get that argument. At this point, I'd ...  ...   \n",
       "1  The blazers and Mavericks (The wests 5 and 6 s...  ...   \n",
       "2                            They're favored to win.  ...   \n",
       "5                   do you find ariana grande sexy ?  ...   \n",
       "6  What's your weird or unsettling Trick or Treat...  ...   \n",
       "\n",
       "                                            polarity    neg    neu    pos  \\\n",
       "0  {'neg': 0.0, 'neu': 0.337, 'pos': 0.663, 'comp...  0.000  0.337  0.663   \n",
       "1  {'neg': 0.0, 'neu': 0.844, 'pos': 0.156, 'comp...  0.000  0.844  0.156   \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  0.000  1.000  0.000   \n",
       "5  {'neg': 0.0, 'neu': 0.868, 'pos': 0.132, 'comp...  0.000  0.868  0.132   \n",
       "6  {'neg': 0.146, 'neu': 0.854, 'pos': 0.0, 'comp...  0.146  0.854  0.000   \n",
       "\n",
       "   compound                                                pcp  pc_neg pc_neu  \\\n",
       "0    0.6037  {'neg': 0.126, 'neu': 0.657, 'pos': 0.217, 'co...   0.126  0.657   \n",
       "1    0.3400  {'neg': 0.095, 'neu': 0.905, 'pos': 0.0, 'comp...   0.095  0.905   \n",
       "2    0.0000  {'neg': 0.0, 'neu': 0.233, 'pos': 0.767, 'comp...   0.000  0.233   \n",
       "5    0.2259  {'neg': 0.0, 'neu': 0.595, 'pos': 0.405, 'comp...   0.000  0.595   \n",
       "6   -0.0516  {'neg': 0.25, 'neu': 0.517, 'pos': 0.233, 'com...   0.250  0.517   \n",
       "\n",
       "   pc_pos  pc_compund  \n",
       "0   0.217      0.2023  \n",
       "1   0.000     -0.3412  \n",
       "2   0.767      0.7650  \n",
       "5   0.405      0.5267  \n",
       "6   0.233      0.2023  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfsub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "#create column that indicates any elongation in words\n",
    "def has_long(sentence):\n",
    "   elong = re.compile(\"([a-zA-Z])\\\\1{2,}\")\n",
    "   return bool(elong.search(sentence))\n",
    "\n",
    "#df.apply(has_long(df.comment.values), axis=0)\n",
    "dfsub['elong'] = [has_long(i) for i in dfsub['comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2765, 23)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count of comments containing elongated words\n",
    "dfsub[dfsub['elong']==True].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write csv to new file\n",
    "dfsub.to_csv('dfsub.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
